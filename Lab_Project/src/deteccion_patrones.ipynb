{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binarizar las imagenes para poder identificar cual es la del círculo y cual la del cuadrado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import numpy as np\n",
    "import imageio\n",
    "import cv2\n",
    "import copy\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(filenames: List) -> List:\n",
    "    return [imageio.imread(filename) for filename in filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtfra\\AppData\\Local\\Temp\\ipykernel_28256\\283608422.py:2: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  return [imageio.imread(filename) for filename in filenames]\n"
     ]
    }
   ],
   "source": [
    "#Imagenes que queremos para identificar el circulo y el cuadrado: \n",
    "imgs_path = [\"Images/pattern_image_4.jpg\",\"Images/pattern_image_10.jpg\"]\n",
    "imgs_pattern = load_images(imgs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_reference_shapes(ref_images):\n",
    "    references = {}\n",
    "    for name, path in ref_images.items():\n",
    "        # Leer y convertir a escala de grises\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        # Binarizar la imagen\n",
    "        _, binary = cv2.threshold(img, 128, 255, cv2.THRESH_BINARY)\n",
    "        # Detectar contornos\n",
    "        contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        references[name] = contours[0]  # Asumimos un solo contorno por imagen\n",
    "    return references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparar contornos detectados en un frame con las referencias\n",
    "def match_shapes(contour, reference_shapes):\n",
    "    for name, ref_contour in reference_shapes.items():\n",
    "        # Usar comparación de contornos (OpenCV matchShapes)\n",
    "        similarity = cv2.matchShapes(contour, ref_contour, cv2.CONTOURS_MATCH_I1, 0.0)\n",
    "        if similarity < 0.1:  # Umbral ajustable\n",
    "            return name  # Retorna el nombre del patrón coincidente\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detectar la posición del lápiz en el frame\n",
    "def detect_pencil_position(frame):\n",
    "    # Convertir a espacio de color HSV\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    # Rango de color para el lápiz (ajustar valores según el color del lápiz)\n",
    "    lower_red = np.array([0, 120, 70])  # Limite inferior de rojo\n",
    "    upper_red = np.array([10, 255, 255])  # Limite superior de rojo\n",
    "    mask = cv2.inRange(hsv, lower_red, upper_red)\n",
    "    \n",
    "    # Encontrar contornos del lápiz\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if contours:\n",
    "        # Tomar el contorno más grande como lápiz\n",
    "        pencil_contour = max(contours, key=cv2.contourArea)\n",
    "        # Calcular el centroide del lápiz\n",
    "        M = cv2.moments(pencil_contour)\n",
    "        if M[\"m00\"] != 0:\n",
    "            cx = int(M[\"m10\"] / M[\"m00\"])\n",
    "            cy = int(M[\"m01\"] / M[\"m00\"])\n",
    "            return (cx, cy)  # Retornar coordenadas del lápiz\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_shapes_in_frame(frame):\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detectar bordes con Sobel\n",
    "    sobel_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    sobel_combined = cv2.magnitude(sobel_x, sobel_y)\n",
    "\n",
    "    # Normalizar y binarizar\n",
    "    sobel_normalized = np.uint8(255 * sobel_combined / np.max(sobel_combined))\n",
    "    _, binary = cv2.threshold(sobel_normalized, 50, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Encontrar contornos\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    return contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shape_center(shape_name, shapes, reference_shapes):\n",
    "    for contour in shapes:\n",
    "        matched_shape = match_shapes(contour, reference_shapes)\n",
    "        if matched_shape == shape_name:\n",
    "            # Calcular centroide\n",
    "            M = cv2.moments(contour)\n",
    "            if M[\"m00\"] != 0:\n",
    "                cx = int(M[\"m10\"] / M[\"m00\"])\n",
    "                cy = int(M[\"m01\"] / M[\"m00\"])\n",
    "                return (cx, cy)  # Coordenadas del centro\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video_with_phases(video_path, ref_images):\n",
    "    # Cargar referencias (círculo y cuadrado)\n",
    "    reference_shapes = load_reference_shapes(ref_images)\n",
    "    \n",
    "    # Estado inicial\n",
    "    current_phase = 0  # Comenzamos fuera de las fases (0 = inicio)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Detectar formas y posición del lápiz\n",
    "        shapes = detect_shapes_in_frame(frame)\n",
    "        detected_shapes = [match_shapes(c, reference_shapes) for c in shapes]\n",
    "        pencil_pos = detect_pencil_position(frame)\n",
    "\n",
    "        if pencil_pos and \"circle\" in detected_shapes and \"square\" in detected_shapes:\n",
    "            # Obtener posiciones de las figuras\n",
    "            circle_pos = get_shape_center(\"circle\", shapes, reference_shapes)\n",
    "            square_pos = get_shape_center(\"square\", shapes, reference_shapes)\n",
    "\n",
    "            # Calcular coordenadas relativas\n",
    "            dx, dy = pencil_pos[0] - circle_pos[0], pencil_pos[1] - circle_pos[1]\n",
    "            circle_radius = int(np.sqrt(cv2.contourArea(shapes[0]) / np.pi))\n",
    "\n",
    "            x, y, w, h = cv2.boundingRect(shapes[1])\n",
    "            square_left, square_right = x, x + w\n",
    "            square_top, square_bottom = y, y + h\n",
    "\n",
    "            # Determinar la fase actual\n",
    "            if pencil_pos[0] < min(circle_pos[0], square_pos[0]):\n",
    "                phase = 1\n",
    "            elif dx**2 + dy**2 <= circle_radius**2:\n",
    "                phase = 2\n",
    "            elif square_left <= pencil_pos[0] <= square_right and square_top <= pencil_pos[1] <= square_bottom:\n",
    "                phase = 3\n",
    "            elif pencil_pos[0] > max(circle_pos[0], square_pos[0]):\n",
    "                phase = 4\n",
    "            else:\n",
    "                phase = current_phase  # Mantén la fase si no cambió\n",
    "\n",
    "            # Validar si la transición es válida\n",
    "            if phase > current_phase:  # Cambio correcto a la siguiente fase\n",
    "                print(f\"Transición: Fase {current_phase} → Fase {phase}\")\n",
    "                current_phase = phase\n",
    "            elif phase < current_phase:  # Orden incorrecto\n",
    "                print(f\"¡Fallo! Transición inválida: Fase {current_phase} → Fase {phase}\")\n",
    "                current_phase = -1  # Marcar fallo\n",
    "                break\n",
    "            elif phase == current_phase:  # Sin cambio\n",
    "                print(f\"Fase actual: {current_phase}, sin cambio.\")\n",
    "\n",
    "            # Mostrar la fase actual en el frame\n",
    "            if current_phase > 0:\n",
    "                cv2.putText(frame, f\"Fase: {current_phase}\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)\n",
    "            else:\n",
    "                cv2.putText(frame, \"Fallo detectado\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "        else:\n",
    "            print(\"Formas no detectadas o lápiz no encontrado.\")\n",
    "\n",
    "        # Mostrar el frame\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "        # Presionar 'q' para salir\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Resultado final\n",
    "    if current_phase == 4:\n",
    "        print(\"Contraseña correcta\")\n",
    "    else:\n",
    "        print(\"Contraseña incorrecta. No se ha pasado efectivamente por los patrones.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
